{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Burrows's Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(filename):\n",
    "    '''open text file and return list of tokens'''\n",
    "    text = open(filename, 'r').read().lower()\n",
    "    tokens = [word for word in re.split('\\W', text) if word != '']\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = {}\n",
    "samples = ['Gratian0', 'Gratian1', 'Gratian2']\n",
    "filenames = [sample + '.txt' for sample in samples]\n",
    "for i in range(len(samples)):\n",
    "   lengths[samples[i]] = len(tokenize(filenames[i]))\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occurrences(tokens):\n",
    "    '''create and return token occurrence dictionary'''\n",
    "    types = list(set(tokens))\n",
    "    tmp = dict.fromkeys(types, 0)\n",
    "    for token in tokens: tmp[token] += 1\n",
    "    occurrences = {\n",
    "        key: value for key, value in sorted(tmp.items(),\n",
    "        key = lambda item: (-item[1], item[0]))\n",
    "    }\n",
    "    return occurrences\n",
    "\n",
    "def features(texts, n):\n",
    "    corpus = []\n",
    "    for text in texts:\n",
    "        corpus += tokenize(text + '.txt')\n",
    "    features = list(occurrences(corpus).keys())[:n]\n",
    "    return features\n",
    "\n",
    "mfws = features(samples, 4)\n",
    "mfws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counts(features, subcorpora):\n",
    "    columns = {}\n",
    "    for subcorpus in subcorpora:\n",
    "        columns[subcorpus] = []\n",
    "        tokens = tokenize(subcorpus + '.txt')\n",
    "        all = occurrences(tokens)\n",
    "        for feature in features:\n",
    "            columns[subcorpus].append(all.get(feature, 0))\n",
    "    return columns\n",
    "\n",
    "counts(mfws, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once we've gotten to this point, we've gathered all the preliminary information we need, and are ready to move the analysis into Pandas dataframes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_counts = pd.DataFrame(counts(mfws, samples), index = mfws)\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lengths = pd.DataFrame(lengths, index = ['words'])\n",
    "df_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explain use of occurrences per 1,000 words instead of percent here. Using occurrences per 1,000 words is more convenient than using percentages, because at that scale the word frequency values we are concerned with (at least most them) are greater than 1.0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = (df_counts / df_lengths.values) * 1000\n",
    "frequencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the point where we need to temporarily drop the Gratian0 column. We're only interested at this point in calculating the mean and sample standard deviation of the values in the two columns we're comparing the candidate to: Gratian1 and Gratian2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = frequencies[['Gratian1', 'Gratian2']]\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = selected.mean(axis = 1).to_frame('mean')\n",
    "means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$s=\\sqrt{\\frac{1}{N - 1}\\sum_{i=1}^N(x_i-\\bar{x})^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = selected.std(axis = 1).to_frame('std')\n",
    "stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z=\\frac{x - \\bar{x}}{s}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = (frequencies - means.values) / stds.values\n",
    "zs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Again, remember that the means and standard deviations have been computed from the values in the Gratian1 and Gratian2 columns *only*!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, break the consolidated z-scores dateframe into two dataframes: one for the hypothetical case statements (*themata*), the other for the first- and second recension *dicta* (including the *dicta* from *de Pen*.) with which we want to compare the case statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = zs[['Gratian0']]\n",
    "b = zs[['Gratian1', 'Gratian2']]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = (b - a.values).abs()\n",
    "c = (b - a.values)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c.mean(axis = 1)).mean(axis = 0)\n",
    "c.sum(axis = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
